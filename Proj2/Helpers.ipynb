{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Helpers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9bVz7w6dlfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import Tensor, LongTensor, FloatTensor\n",
        "import math\n",
        "import modules as m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxEz8O6I1qy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_disc_data(n = 1000):\n",
        "  '''\n",
        "  Generates disc data, sampled uniformly in [0,1]Â², around center C(1/2,1/2) and radius r = 1/sqrt(2*pi)\n",
        "  '''\n",
        "\n",
        "  center = torch.Tensor([[0.5, 0.5]])\n",
        "  input_coords = torch.rand(n,2)\n",
        "  L2_distances = torch.norm((input_coords - center).abs(), 2, 1, True)\n",
        "  targets = L2_distances.mul(math.sqrt(2*math.pi)).sub(1).sign().sub(1).div(2).abs().long()\n",
        "  return input_coords, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed5QB09_1q2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(inputs, targets, train_ratio = 0.7, validation_ratio = 0.1, test_ratio = 0.2):\n",
        "  '''\n",
        "  Splits the data into a training, a validation and a test set\n",
        "  '''\n",
        "\n",
        "  train_size = math.floor(inputs.size()[0] * train_ratio)\n",
        "  validation_size = math.floor(inputs.size()[0] * validation_ratio)\n",
        "  test_size = math.floor(inputs.size()[0] * test_ratio)\n",
        "\n",
        "  train_inputs  = inputs.narrow(0, 0, train_size)\n",
        "  train_targets = targets.narrow(0, 0, train_size)\n",
        "\n",
        "  validation_inputs  = inputs.narrow(0, train_size, validation_size)\n",
        "  validation_targets = targets.narrow(0, train_size, validation_size)\n",
        "\n",
        "  test_inputs  = inputs.narrow(0, train_size+validation_size, test_size)\n",
        "  test_targets = targets.narrow(0, train_size+validation_size, test_size)\n",
        "\n",
        "  return train_inputs, train_targets, validation_inputs, validation_targets, test_inputs, test_targets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-714GNlsVKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_one_hot_labels(input, target):\n",
        "    '''\n",
        "    Converts targets to one-hot labels of values -1 and 1\n",
        "    '''\n",
        "    \n",
        "    tmp = input.new(target.size(0), target.max() + 1).fill_(-1)\n",
        "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
        "    return tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvh1n5LAAjpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_input, train_target, validation_input, validation_target, model, optimizer, nb_epochs = 100):\n",
        "  '''\n",
        "  Trains the model with the given optimizer, outputs the trained model along with the train and validation error lists,\n",
        "  prints both train and validation errors\n",
        "  '''\n",
        "\n",
        "  nb_train_samples = train_input.size(0)\n",
        "  nb_val_samples = validation_input.size(0)\n",
        "\n",
        "  #Initialization of the output error lists\n",
        "  train_error      = []\n",
        "  validation_error = []\n",
        "\n",
        "  #Convert target values using one hot encoding\n",
        "  train_target = convert_to_one_hot_labels(train_input, train_target)\n",
        "  validation_target = convert_to_one_hot_labels(validation_input, validation_target)\n",
        "\n",
        "\n",
        "  for e in range(nb_epochs):\n",
        "\n",
        "    #Training\n",
        "\n",
        "    loss = 0\n",
        "    nb_train_errors = 0\n",
        "\n",
        "    for n in range(nb_train_samples):\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      target = train_target[n]\n",
        "      target_tuple = [target[0], target[1]]\n",
        "      target_index = target_tuple.index(max(target_tuple))\n",
        "\n",
        "      pred = model.forward(train_input[n])\n",
        "      pred_tuple = [pred[0], pred[1]]\n",
        "      pred_index = pred_tuple.index(max(pred_tuple))\n",
        "\n",
        "      if int(target_index) != int(pred_index) : nb_train_errors += 1\n",
        "      \n",
        "      loss += m.MSELoss(target.float(), pred) \n",
        "      dl_loss = m.dl_MSELoss(target.float(), pred)\n",
        "\n",
        "      model.backward(dl_loss)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "    train_error.append((100 * nb_train_errors) / nb_train_samples)\n",
        "\n",
        "\n",
        "    #Validation\n",
        "\n",
        "    nb_validation_errors = 0\n",
        "\n",
        "    for n in range(nb_val_samples):\n",
        "\n",
        "      target = validation_target[n]\n",
        "      target_tuple = [target[0], target[1]]\n",
        "      target_index = target_tuple.index(max(target_tuple))\n",
        "\n",
        "      pred = model.forward(validation_input[n])\n",
        "      pred_tuple = [pred[0], pred[1]]\n",
        "      pred_index = pred_tuple.index(max(pred_tuple))\n",
        "\n",
        "      if int(target_index) != int(pred_index) : nb_validation_errors += 1\n",
        "    \n",
        "    validation_error.append((100 * nb_validation_errors) / nb_val_samples)\n",
        "  \n",
        "\n",
        "    #Print intermediate loss and error results (each 10 epochs)\n",
        "\n",
        "    if (e % 10) == 0:\n",
        "      print('Epoch : {:d}, Train_loss {:.02f}, Train_error {:.02f}%, Validation_error {:.02f}%'\n",
        "      .format(e, loss, (100 * nb_train_errors)/nb_train_samples, (100 * nb_validation_errors)/nb_val_samples))\n",
        "\n",
        "  return model, train_error, validation_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBdSGYbIcUiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(trained_model, test_input, test_target):\n",
        "  '''\n",
        "  Tests the trained model with the new data, prints test error\n",
        "  '''\n",
        "\n",
        "  nb_test_samples = test_input.size(0)\n",
        "  test_target = convert_to_one_hot_labels(test_input, test_target)\n",
        "  nb_test_errors = 0\n",
        "\n",
        "  for n in range(nb_test_samples):\n",
        "\n",
        "    target = test_target[n]\n",
        "    target_tuple = [target[0], target[1]]\n",
        "    target_index = target_tuple.index(max(target_tuple))\n",
        "\n",
        "    pred = trained_model.forward(test_input[n])\n",
        "    pred_tuple = [pred[0], pred[1]]\n",
        "    pred_index = pred_tuple.index(max(pred_tuple))\n",
        "\n",
        "    if int(target_index) != int(pred_index) : nb_test_errors += 1\n",
        "\n",
        "  print('test_error {:.02f}%'.format(((100 * nb_test_errors) / nb_test_samples)))\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qicP09qgMp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}